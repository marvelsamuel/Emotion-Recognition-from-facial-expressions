# Emotion-Recognition-from-facial-expressions
### Introduction
This repository contains the implementation of an emotion recognition model based on the VGG16 architecture with additional layers. The model is trained on the FER 2013 dataset, which consists of facial images labeled with various emotion classes. The goal of this project is to build a deep learning model that can accurately recognize emotions from facial expressions.

### Dataset
The FER 2013 dataset is used for training and evaluating the emotion recognition model. It contains 48x48 grayscale images of faces labeled with one of the following seven emotion classes: angry, disgust, fear, happy, sad, surprise, and neutral. The dataset consists of approximately 35,000 images divided into training, validation, and test sets.

To use this repository, you need to download the FER 2013 dataset and place it you can download it from this link https://www.kaggle.com/datasets/msambare/fer2013 .

### Model Architecture
The emotion recognition model is built using the VGG16 architecture as a base and extended with additional layers. The VGG16 model is a deep convolutional neural network with 16 layers, which has shown excellent performance in image recognition tasks.

The additional layers are added on top of the VGG16 base to fine-tune the model for emotion recognition. 
